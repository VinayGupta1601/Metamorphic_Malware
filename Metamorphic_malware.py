# -*- coding: utf-8 -*-
"""Mtech_Thesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yqBh0lDgXO5VyGmnO4h-F0iO8JDk0pnm
"""

import pandas as pd

malData = pd.read_csv("/content/drive/MyDrive/MalwareData.csv",sep = "|")

legit = malData[0:41323].drop(["legitimate"], axis=1)
mal = malData[41324::].drop(["legitimate"], axis=1)

print(malData.head())

print("Legit has %s samples and %s features"%(legit.shape[0],legit.shape[1]))
print("Malware has %s samples and %s features"%(mal.shape[0],mal.shape[1]))

import sklearn
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split

Data_in = malData.drop(['Name', 'md5', 'legitimate'], axis=1).values
labels = malData['legitimate'].values

extratrees = ExtraTreesClassifier().fit(Data_in, labels)
select = SelectFromModel(extratrees, prefit=True)
Data_new = select.transform(Data_in)
print(Data_in.shape,Data_new.shape)

import numpy as np
features = Data_new.shape[1]
importances = extratrees.feature_importances_
indices = np.argsort(importances)[::-1]

for f in range(features):
  print("%d"%(f+1),malData.columns[2+indices[f]],importances[indices[f]])

"""**RandomForestClassifier**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
legit_train, legit_test, mal_train, mal_test = train_test_split(Data_new, labels ,test_size=0.2)
classif = RandomForestClassifier(n_estimators=50)

classif.fit(legit_train,mal_train)

legit_train

print("the score is :",classif.score(legit_test,mal_test)*100) #accuracy or precision



from sklearn.metrics import confusion_matrix

result = classif.predict(legit_test)
conf_mat = confusion_matrix(mal_test,result)

conf_mat

print("false positive:",conf_mat[0][1]/sum(conf_mat[0])*100)
print("false negative:",conf_mat[1][0]/sum(conf_mat[1])*100)

"""**GradientBoostingClassifier**"""

from sklearn.ensemble import GradientBoostingClassifier

grad_boost = GradientBoostingClassifier(n_estimators=50)
grad_boost.fit(legit_train,mal_train)

print("Gradient Boosting score:", grad_boost.score(legit_test,mal_test)*100)

"""**Gaussian Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(legit_train,mal_train)

print("GaussianNB Score:", nb.score(legit_test,mal_test)*100)

from sklearn.ensemble import BaggingRegressor
import xgboost as xgb
model = BaggingRegressor(base_estimator=xgb.XGBRegressor())
model.fit(legit_train,mal_train)

print("xgboost", model.score(legit_test,mal_test)*100)